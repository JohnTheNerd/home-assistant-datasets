# serializer version: 1
# name: test_dataset_cards
  list([
    DatasetCard(name='assist', description='A dataset built to exercise the Home Assistant LLM API. The homes for this\ndataset were synthetically generated using gpt-3.5, and then manually curated\nto exercise the Home Assistant intents for controlling devices. The sentences\nwere made intentionally more difficult than the existing assistant NLP for\nshowcasing larger model reasoning capabilities.', urls=['https://github.com/allenporter/home-assistant-datasets/tree/main/datasets/assist', 'https://developers.home-assistant.io/blog/2024/05/20/llm-api/'], count=5, version='v2', path='datasets/assist', config_entry_data=None, config_entry_options=None),
    DatasetCard(name='assist-mini', description='A dataset built to exercise the Home Assistant LLM API. The homes for this\ndataset were synthetically generated using gpt-3.5, and then simplified for\nexercising smaller LLMs. The use cases are not intended to be very tricky or\ncomplicated and aimed at a smaller context window. The number of devices/entities\nin each test is intentionally small (e.g. typically under 5 entities per test) to focus\non tool calling capabilities rather than context retrieval.', urls=['https://github.com/allenporter/home-assistant-datasets/tree/main/datasets/assist-mini'], count=4, version='v1', path='datasets/assist-mini', config_entry_data=None, config_entry_options=None),
    DatasetCard(name='automations', description='A dataset for evaluating automation generation. The homes for this dataset were\nsynthetically generated using gpt-3.5. This dataset is in development and contains\njust a few initial examples. Each benchmark creates a synthetic home fixture\nand configures the entities with a particular state, then asks for an automation\nfor a specific set of devices.\n\nThe benchmark loads a synthetic home and runs pytest with Home Assistant to\nrun through scenarios that should trigger the automation. It also gives points\nfor getting inputs correct and each problem benchmark exercises different\nscenarios that add to the overall score. The various scenarios are not weighted.', urls=['https://github.com/allenporter/home-assistant-datasets/tree/main/datasets/automations'], count=None, version='v0', path='datasets/automations', config_entry_data=None, config_entry_options={'llm_hass_api': '', 'max_tokens': 4096}),
    DatasetCard(name='intents', description='A dataset built form the Home Assitant intents repo, modeled after existing\nNLP test cases for the assistant pipeline. This is mean to reuse the\ntests that already exist for the NLP, which turns out to expose some\nweaknesses or differences of interpretation of tasks. It also is a very large\nhome which is challenging for smaller models given the ~100 or so devices. Lastly,\nthere are some tests that have subtle mismatches that are reasonable (e.g.\n"minimium brightness" tests)', urls=['https://github.com/allenporter/home-assistant-datasets/tree/main/datasets/intents', 'https://github.com/home-assistant/intents'], count=None, version=None, path='datasets/intents', config_entry_data=None, config_entry_options=None),
    DatasetCard(name='questions', description='A dataset built to exercise question and answering capabilities of the Home\nAssistant LLM API. The homes for this dataset were synthetically generated\nand then manually curated to exercise the Home Assistant\nintents for querying device state.\n\nThis dataset is currently in development and is not yet complete. It may\ncontain bugs or incomplete data. We welcome contributions to improve the\ndataset. Please see repo docs for more information on how to contribute.', urls=['https://github.com/allenporter/home-assistant-datasets/tree/main/datasets/questions'], count=10, version=None, path='datasets/questions', config_entry_data=None, config_entry_options=None),
  ])
# ---
