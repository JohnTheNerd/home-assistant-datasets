---
- model_id-task_name: claude-3-5-haiku-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-5-haiku-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-5-haiku-eval-test_expect_response
  good_percent: 86.3%
  confidence_interval: 5.1%
  good: 151
  total: 175
- model_id-task_name: claude-3-5-haiku-eval-test_expected_states
  good_percent: 85.7%
  confidence_interval: 3.2%
  good: 402
  total: 469
- model_id-task_name: claude-3-7-sonnet-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-7-sonnet-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-7-sonnet-eval-test_expect_response
  good_percent: 83.1%
  confidence_interval: 5.7%
  good: 138
  total: 166
- model_id-task_name: claude-3-7-sonnet-eval-test_expected_states
  good_percent: 89.7%
  confidence_interval: 2.8%
  good: 400
  total: 446
- model_id-task_name: gemini-1.5-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-1.5-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-1.5-flash-eval-test_expect_response
  good_percent: 64.6%
  confidence_interval: 7.1%
  good: 113
  total: 175
- model_id-task_name: gemini-1.5-flash-eval-test_expected_states
  good_percent: 88.9%
  confidence_interval: 2.8%
  good: 418
  total: 470
- model_id-task_name: gemini-2.0-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-eval-test_expect_response
  good_percent: 77.7%
  confidence_interval: 6.2%
  good: 136
  total: 175
- model_id-task_name: gemini-2.0-flash-eval-test_expected_states
  good_percent: 69.1%
  confidence_interval: 4.2%
  good: 325
  total: 470
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_response
  good_percent: 57.1%
  confidence_interval: 7.3%
  good: 100
  total: 175
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expected_states
  good_percent: 66.4%
  confidence_interval: 4.3%
  good: 312
  total: 470
- model_id-task_name: gemini-2.5-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-flash-eval-test_expect_response
  good_percent: 69.7%
  confidence_interval: 6.8%
  good: 122
  total: 175
- model_id-task_name: gemini-2.5-flash-eval-test_expected_states
  good_percent: 88.1%
  confidence_interval: 2.9%
  good: 414
  total: 470
- model_id-task_name: gemini-2.5-pro-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-pro-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-pro-eval-test_expect_response
  good_percent: 82.3%
  confidence_interval: 5.7%
  good: 144
  total: 175
- model_id-task_name: gemini-2.5-pro-eval-test_expected_states
  good_percent: 91.5%
  confidence_interval: 2.5%
  good: 431
  total: 471
- model_id-task_name: gpt-3.5-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-3.5-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-3.5-eval-test_expect_response
  good_percent: 74.1%
  confidence_interval: 6.5%
  good: 129
  total: 174
- model_id-task_name: gpt-3.5-eval-test_expected_states
  good_percent: 85.5%
  confidence_interval: 3.2%
  good: 402
  total: 470
- model_id-task_name: gpt-4.1-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-eval-test_expect_response
  good_percent: 84.6%
  confidence_interval: 5.4%
  good: 148
  total: 175
- model_id-task_name: gpt-4.1-eval-test_expected_states
  good_percent: 81.6%
  confidence_interval: 3.5%
  good: 385
  total: 472
- model_id-task_name: gpt-4.1-mini-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-mini-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-mini-eval-test_expect_response
  good_percent: 79.4%
  confidence_interval: 6.0%
  good: 139
  total: 175
- model_id-task_name: gpt-4.1-mini-eval-test_expected_states
  good_percent: 86.6%
  confidence_interval: 3.1%
  good: 406
  total: 469
- model_id-task_name: gpt-4.1-nano-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-nano-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-nano-eval-test_expect_response
  good_percent: 68.0%
  confidence_interval: 6.9%
  good: 119
  total: 175
- model_id-task_name: gpt-4.1-nano-eval-test_expected_states
  good_percent: 74.1%
  confidence_interval: 4.0%
  good: 347
  total: 468
- model_id-task_name: gpt-4o-mini-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4o-mini-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4o-mini-eval-test_expect_response
  good_percent: 76.6%
  confidence_interval: 6.3%
  good: 134
  total: 175
- model_id-task_name: gpt-4o-mini-eval-test_expected_states
  good_percent: 85.1%
  confidence_interval: 3.2%
  good: 400
  total: 470

